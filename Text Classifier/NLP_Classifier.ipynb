{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "%pip install datasets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (4.40.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: regex!=2019.12.17 in /home/azureuser/.local/lib/python3.8/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: numpy>=1.17 in /home/azureuser/.local/lib/python3.8/site-packages (from transformers) (1.24.4)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (6.0)\nRequirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: packaging>=20.0 in /home/azureuser/.local/lib/python3.8/site-packages (from transformers) (23.2)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (3.14.0)\nRequirement already satisfied: tqdm>=4.27 in /home/azureuser/.local/lib/python3.8/site-packages (from transformers) (4.66.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/azureuser/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->transformers) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->transformers) (3.4)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: datasets in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (2.19.0)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (3.14.0)\nRequirement already satisfied: tqdm>=4.62.1 in /home/azureuser/.local/lib/python3.8/site-packages (from datasets) (4.66.2)\nRequirement already satisfied: xxhash in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (6.0)\nRequirement already satisfied: pyarrow-hotfix in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pyarrow>=12.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (16.0.0)\nRequirement already satisfied: numpy>=1.17 in /home/azureuser/.local/lib/python3.8/site-packages (from datasets) (1.24.4)\nRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: aiohttp in /home/azureuser/.local/lib/python3.8/site-packages (from datasets) (3.9.3)\nRequirement already satisfied: packaging in /home/azureuser/.local/lib/python3.8/site-packages (from datasets) (23.2)\nRequirement already satisfied: multiprocess in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /home/azureuser/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /home/azureuser/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /home/azureuser/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /home/azureuser/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /home/azureuser/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/azureuser/.local/lib/python3.8/site-packages (from huggingface-hub>=0.21.2->datasets) (4.10.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.16)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from datasets import load_dataset"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-04-30 13:51:58.525560: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-04-30 13:51:59.177513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2024-04-30 13:51:59.177545: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2024-04-30 13:52:01.616958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2024-04-30 13:52:01.617218: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2024-04-30 13:52:01.617237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n/home/azureuser/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:03.687754Z",
          "iopub.status.busy": "2023-01-20T09:18:03.687439Z",
          "iopub.status.idle": "2023-01-20T09:18:09.777608Z",
          "shell.execute_reply": "2023-01-20T09:18:09.776647Z",
          "shell.execute_reply.started": "2023-01-20T09:18:03.687681Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485140088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-04-30 13:52:31.749287: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2024-04-30 13:52:31.749343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (michael2): /proc/driver/nvidia/version does not exist\n2024-04-30 13:52:31.751829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:09.780213Z",
          "iopub.status.busy": "2023-01-20T09:18:09.779481Z",
          "iopub.status.idle": "2023-01-20T09:18:30.911882Z",
          "shell.execute_reply": "2023-01-20T09:18:30.910893Z",
          "shell.execute_reply.started": "2023-01-20T09:18:09.780171Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485158237
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:30.913871Z",
          "iopub.status.busy": "2023-01-20T09:18:30.913507Z",
          "iopub.status.idle": "2023-01-20T09:18:37.1918Z",
          "shell.execute_reply": "2023-01-20T09:18:37.190825Z",
          "shell.execute_reply.started": "2023-01-20T09:18:30.913832Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485158391
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(['Hello world', 'Hi how are you'], padding=True, truncation=True,\n",
        "                  return_tensors='tf')\n",
        "inputs"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "{'input_ids': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[ 101, 7592, 2088,  102,    0,    0],\n       [ 101, 7632, 2129, 2024, 2017,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[1, 1, 1, 1, 0, 0],\n       [1, 1, 1, 1, 1, 1]], dtype=int32)>}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:37.195108Z",
          "iopub.status.busy": "2023-01-20T09:18:37.194473Z",
          "iopub.status.idle": "2023-01-20T09:18:37.212876Z",
          "shell.execute_reply": "2023-01-20T09:18:37.211923Z",
          "shell.execute_reply.started": "2023-01-20T09:18:37.195069Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485158550
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(inputs)\n",
        "output"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(2, 6, 768), dtype=float32, numpy=\narray([[[-0.16888368,  0.13606334, -0.13940026, ..., -0.6251122 ,\n          0.05217217,  0.36714512],\n        [-0.36327457,  0.14121945,  0.8799881 , ...,  0.10432968,\n          0.28875685,  0.37267888],\n        [-0.69859535, -0.69879794,  0.06450231, ..., -0.2210361 ,\n          0.00986825, -0.5939789 ],\n        [ 0.830983  ,  0.12366661, -0.15119042, ...,  0.1030962 ,\n         -0.6779266 , -0.26285228],\n        [-0.4026664 , -0.01928248,  0.57325083, ..., -0.20656833,\n          0.0233856 ,  0.20126273],\n        [-0.6228405 , -0.27453458,  0.18117645, ..., -0.1294482 ,\n         -0.03839105, -0.05733154]],\n\n       [[ 0.09286527, -0.02636384, -0.12239321, ..., -0.21063548,\n          0.17386332,  0.17250988],\n        [ 0.40742004, -0.05930935,  0.5523459 , ..., -0.67905545,\n          0.6555743 , -0.2945643 ],\n        [-0.21155259, -0.6858636 , -0.4628085 , ...,  0.15278348,\n          0.5977411 , -0.9102019 ],\n        [ 0.39921236, -1.320781  , -0.08008818, ..., -0.3212549 ,\n          0.25572896, -0.5780445 ],\n        [-0.07565233, -1.3393835 ,  0.18163005, ...,  0.07461107,\n          0.40318492, -0.70799875],\n        [ 0.5988927 , -0.28409442, -0.34899253, ...,  0.3042009 ,\n         -0.43675527, -0.20969628]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\narray([[-0.9061534 , -0.31115302, -0.6216534 , ..., -0.30575198,\n        -0.64009374,  0.9166174 ],\n       [-0.9309668 , -0.3380702 , -0.6216153 , ..., -0.44018874,\n        -0.6812884 ,  0.93488955]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:37.214288Z",
          "iopub.status.busy": "2023-01-20T09:18:37.213951Z",
          "iopub.status.idle": "2023-01-20T09:18:37.322919Z",
          "shell.execute_reply": "2023-01-20T09:18:37.321878Z",
          "shell.execute_reply.started": "2023-01-20T09:18:37.214255Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485159092
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = load_dataset('SetFit/emotion')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Repo card metadata block was not found. Setting CardData to empty.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:37.326069Z",
          "iopub.status.busy": "2023-01-20T09:18:37.325752Z",
          "iopub.status.idle": "2023-01-20T09:18:43.700967Z",
          "shell.execute_reply": "2023-01-20T09:18:43.700024Z",
          "shell.execute_reply.started": "2023-01-20T09:18:37.326042Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485160984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:43.703397Z",
          "iopub.status.busy": "2023-01-20T09:18:43.702691Z",
          "iopub.status.idle": "2023-01-20T09:18:43.711197Z",
          "shell.execute_reply": "2023-01-20T09:18:43.709938Z",
          "shell.execute_reply.started": "2023-01-20T09:18:43.703346Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485161120
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:43.713746Z",
          "iopub.status.busy": "2023-01-20T09:18:43.713028Z",
          "iopub.status.idle": "2023-01-20T09:18:43.720576Z",
          "shell.execute_reply": "2023-01-20T09:18:43.719268Z",
          "shell.execute_reply.started": "2023-01-20T09:18:43.713713Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485161249
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:43.723013Z",
          "iopub.status.busy": "2023-01-20T09:18:43.722305Z",
          "iopub.status.idle": "2023-01-20T09:18:46.641566Z",
          "shell.execute_reply": "2023-01-20T09:18:46.640256Z",
          "shell.execute_reply.started": "2023-01-20T09:18:43.72298Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485161370
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:46.646206Z",
          "iopub.status.busy": "2023-01-20T09:18:46.645858Z",
          "iopub.status.idle": "2023-01-20T09:18:46.656491Z",
          "shell.execute_reply": "2023-01-20T09:18:46.655557Z",
          "shell.execute_reply.started": "2023-01-20T09:18:46.646174Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485161505
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting 'input_ids', 'attention_mask', 'token_type_ids', and 'label'\n",
        "# to the tensorflow format. Now if you access this dataset you will get these\n",
        "# columns in `tf.Tensor` format\n",
        "\n",
        "emotions_encoded.set_format('tf', \n",
        "                            columns=['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n",
        "\n",
        "# setting BATCH_SIZE to 64.\n",
        "BATCH_SIZE = 64*2\n",
        "\n",
        "def order(inp):\n",
        "    '''\n",
        "    This function will group all the inputs of BERT\n",
        "    into a single dictionary and then output it with\n",
        "    labels.\n",
        "    '''\n",
        "    data = list(inp.values())\n",
        "    return {\n",
        "        'input_ids': data[1],\n",
        "        'attention_mask': data[2],\n",
        "        'token_type_ids': data[3]\n",
        "    }, data[0]\n",
        "\n",
        "# converting train split of `emotions_encoded` to tensorflow format\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['train'][:])\n",
        "# set batch_size and shuffle\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\n",
        "# map the `order` function\n",
        "train_dataset = train_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# ... doing the same for test set ...\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['test'][:])\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:46.658083Z",
          "iopub.status.busy": "2023-01-20T09:18:46.65777Z",
          "iopub.status.idle": "2023-01-20T09:18:47.061486Z",
          "shell.execute_reply": "2023-01-20T09:18:47.060535Z",
          "shell.execute_reply.started": "2023-01-20T09:18:46.658056Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485161638
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp, out = next(iter(train_dataset)) # a batch from train_dataset\n",
        "print(inp, '\\n\\n', out)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'input_ids': <tf.Tensor: shape=(128, 87), dtype=int64, numpy=\narray([[ 101, 1045, 2514, ...,    0,    0,    0],\n       [ 101, 1045, 2323, ...,    0,    0,    0],\n       [ 101, 1045, 2031, ...,    0,    0,    0],\n       ...,\n       [ 101, 1045, 2481, ...,    0,    0,    0],\n       [ 101, 1045, 3432, ...,    0,    0,    0],\n       [ 101, 1045, 2064, ...,    0,    0,    0]])>, 'attention_mask': <tf.Tensor: shape=(128, 87), dtype=int64, numpy=\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])>, 'token_type_ids': <tf.Tensor: shape=(128, 87), dtype=int64, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])>} \n\n tf.Tensor(\n[1 1 0 1 2 1 2 3 1 4 0 1 1 2 0 1 0 4 1 1 1 0 3 0 4 1 2 3 0 0 1 0 0 4 3 0 1\n 1 1 2 3 1 4 3 4 1 1 1 3 0 0 0 4 1 4 1 0 1 2 1 1 1 1 1 1 1 0 3 0 2 0 2 0 1\n 0 4 1 3 1 4 3 0 0 0 0 1 1 1 0 1 1 3 0 1 1 4 3 0 0 0 0 0 3 1 0 1 0 0 0 0 1\n 1 4 0 2 3 3 1 0 0 1 3 2 1 4 1 3 1], shape=(128,), dtype=int64)\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:47.063797Z",
          "iopub.status.busy": "2023-01-20T09:18:47.063232Z",
          "iopub.status.idle": "2023-01-20T09:18:47.197882Z",
          "shell.execute_reply": "2023-01-20T09:18:47.196867Z",
          "shell.execute_reply.started": "2023-01-20T09:18:47.063759Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485161772
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTForClassification(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, bert_model, num_classes):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x = self.bert(inputs)[1]\n",
        "        return self.fc(x)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:47.199664Z",
          "iopub.status.busy": "2023-01-20T09:18:47.199189Z",
          "iopub.status.idle": "2023-01-20T09:18:47.206419Z",
          "shell.execute_reply": "2023-01-20T09:18:47.205181Z",
          "shell.execute_reply.started": "2023-01-20T09:18:47.199627Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485161894
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = BERTForClassification(model, num_classes=6)\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-1),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:47.209035Z",
          "iopub.status.busy": "2023-01-20T09:18:47.207972Z",
          "iopub.status.idle": "2023-01-20T09:18:47.233138Z",
          "shell.execute_reply": "2023-01-20T09:18:47.232304Z",
          "shell.execute_reply.started": "2023-01-20T09:18:47.208857Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485162013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = classifier.fit(\n",
        "    train_dataset,\n",
        "    epochs=3\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/3\n 14/125 [==>...........................] - ETA: 3:24:37 - loss: 48.1279 - accuracy: 0.2148\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 15/125 [==>...........................] - ETA: 3:23:47 - loss: 46.5522 - accuracy: 0.2224"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:18:47.235062Z",
          "iopub.status.busy": "2023-01-20T09:18:47.234445Z",
          "iopub.status.idle": "2023-01-20T09:29:10.433516Z",
          "shell.execute_reply": "2023-01-20T09:29:10.432381Z",
          "shell.execute_reply.started": "2023-01-20T09:18:47.235023Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485092127
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate(test_dataset)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-20T09:56:03.134488Z",
          "iopub.status.busy": "2023-01-20T09:56:03.1341Z",
          "iopub.status.idle": "2023-01-20T09:56:13.390187Z",
          "shell.execute_reply": "2023-01-20T09:56:13.389079Z",
          "shell.execute_reply.started": "2023-01-20T09:56:03.134453Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1714485092142
        }
      }
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30357,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}