{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/llm_parser/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load the sentence-bert model from the HuggingFace model hub\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/llm_parser/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/sentence_bert')\n",
    "model = AutoModel.from_pretrained('deepset/sentence_bert')\n",
    "\n",
    "sentence = 'Who are you voting for in 2020?'\n",
    "labels = ['business', 'art & culture', 'politics']\n",
    "\n",
    "# run inputs through model and mean-pool over the sequence\n",
    "# dimension to get sequence-level representations\n",
    "inputs = tokenizer.batch_encode_plus([sentence] + labels,\n",
    "                                     return_tensors='pt',\n",
    "                                     pad_to_max_length=True)\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "output = model(input_ids, attention_mask=attention_mask)[0]\n",
    "sentence_rep = output[:1].mean(dim=1)\n",
    "label_reps = output[1:].mean(dim=1)\n",
    "\n",
    "# now find the labels with the highest cosine similarities to\n",
    "# the sentence\n",
    "similarities = F.cosine_similarity(sentence_rep, label_reps)\n",
    "closest = similarities.argsort(descending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0045, -0.0274,  0.2156], grad_fn=<SumBackward1>)\n",
      "business 0.004524152725934982\n",
      "art & culture -0.02739686146378517\n",
      "politics 0.2156151533126831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b\"\\xbc\\xc8q'\\xa9\\xa1.\\x89\\xd14\\x9dg\\x8f\\xa7\\xd1hi\\x91\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\"]\n",
      "Bad pipe message: %s [b'Z\\xf6l#\\x0eA\\xcd)\\xfc\\xd1\\xe4\\xa6\\xd8a\\xb9[\\x0b\\x80 \\xfb\\xbd\\x7f\\x0b\\x8dPN\\xbe\\xb6\\xb7Z[#\\x84\\xdb\\xda(\\x8d\\xcf\\xb3\\xc8,\\xa2\\xc3n\\x80!\\x91\\xa0\\x10\\xd3\\x84\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 C[\\xbe\\x07E\\x84\\xfa\\xa9f\\x96L\\x0f\\xd2']\n",
      "Bad pipe message: %s [b\":; ;//l\\xdc\\x07\\xca\\x85\\x99-\\xfa\\x9c\\xb8\\xce\\xc2\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\", b'\\x08\\x08\\x08\\t\\x08\\n\\x08', b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
      "Bad pipe message: %s [b'T\\xf7\\xbc\\xb1:pg\"\\xc5\\xc0\\xf1\\rN\\xf1\\x1f\\xeb\\r\\xf2\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0\\'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19']\n",
      "Bad pipe message: %s [b'\\xe1\\x7f\\xf8+ f\\x7f\\x18\\xdb\\xbdb*\\xd5j\\x1e\\x94Hj\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0']\n",
      "Bad pipe message: %s [b'\\xfc/\\xfc\\xff\\x04\\x0e\\x0cG\\x9c>\\xcd\\x0b\\xe0\\xd5\\xa0\\xdc\\x9a\\x8c\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00']\n",
      "Bad pipe message: %s [b'`^\\xff\\xb3\\xb7\\xbb*\\xec\\xdf\\x15\\x12\\xb8\\xb9\\xfd\\x92~\\xb5\\x1f\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00']\n",
      "Bad pipe message: %s [b\"S\\xa9!\\x90\\x89?~f\\xadU\\xfc[\\xaf\\xb8\\xc0\\x9f!\\x94\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\", b'\\x05\\x02\\x05\\x03', b'\\x04\\x02\\x04', b'\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\n",
      "Bad pipe message: %s [b\"#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\\x03\\x02\\x03\\x03\\x01\\x02\"]\n",
      "Bad pipe message: %s [b'\\x01']\n",
      "Bad pipe message: %s [b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n"
     ]
    }
   ],
   "source": [
    "print(similarities)\n",
    "# print(sentence_rep, label_reps)\n",
    "for i,j in zip(labels, similarities):\n",
    "    print(i,float(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0045, -0.0274,  0.2156], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(similarities)\n",
    "for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: politics \t similarity: 0.2156151533126831\n",
      "label: business \t similarity: 0.004524152725934982\n",
      "label: art & culture \t similarity: -0.02739686146378517\n",
      "Script 1 Ran\n"
     ]
    }
   ],
   "source": [
    "for ind in closest:\n",
    "    print(f'label: {labels[ind]} \\t similarity: {similarities[ind]}')\n",
    "\n",
    "print('Script 1 Ran')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mres\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model pretrained on MNLI\n",
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "\n",
    "# pose sequence as a NLI premise and label (politics) as a hypothesis\n",
    "premise = 'Who are you voting for in 2020?'\n",
    "hypothesis = 'This text is about politics.'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
    "logits = model(input_ids)[0]\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "true_prob = probs[:,1].item() * 100\n",
    "print(f'Probability that the label is true: {true_prob:0.2f}%')\n",
    "print('Script 2 Ran!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "test = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5443,  1.3904]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metric = logits[:,[0,2]]\n",
    "test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0192, 0.9808]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0121, 0.3699, 0.6181]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# print the resulting probabilities (only comparing positive and negative)\n",
    "print(logits[:,[0,2]].softmax(dim=1))\n",
    "\n",
    "# print the resulting probabilities (including the neutral option)\n",
    "print(logits.softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that the label is true: 98.46%\n",
      "Script 3 Ran!\n"
     ]
    }
   ],
   "source": [
    "# USING MODEL RAVI FOUND- Worked!\n",
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('joeddav/bart-large-mnli-yahoo-answers')\n",
    "model = BartForSequenceClassification.from_pretrained('joeddav/bart-large-mnli-yahoo-answers')\n",
    "\n",
    "# pose sequence as a NLI premise and label (politics) as a hypothesis\n",
    "premise = 'Who are you voting for in 2020?'\n",
    "hypothesis = 'This text is about politics.'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt')\n",
    "logits = model(input_ids)[0]\n",
    "\n",
    "# we throw away \"neutral\" (dim 1) and take the probability of\n",
    "# \"entailment\" (2) as the probability of the label being true \n",
    "entail_contradiction_logits = logits[:,[0,2]]\n",
    "probs = entail_contradiction_logits.softmax(dim=1)\n",
    "true_prob = probs[:,1].item() * 100\n",
    "print(f'Probability that the label is true: {true_prob:0.2f}%')\n",
    "print('Script 3 Ran!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/llm_parser/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-04 12:28:33.618307: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 12:28:38.393044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from src.make_models.topic_tagger import Inference\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 12:28:43,990 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar to /tmp/tika-server.jar.\n",
      "2024-06-04 12:28:44,782 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar.md5 to /tmp/tika-server.jar.md5.\n",
      "2024-06-04 12:28:45,188 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(filename=\"/home/azureuser/cloudfiles/code/Users/Michael.Sowter/Deep_Learning_Training/inference.log\", level=logging.INFO, filemode=\"w\")\n",
    "tci = Inference(topic=\"\", logger=logger, pdf_filepath=\"/home/azureuser/cloudfiles/code/Users/Michael.Sowter/Deep_Learning_Training/Text Classifier/Input_Data/Overview.pdf\", out_filepath=\"/home/azureuser/cloudfiles/code/Users/Michael.Sowter/Deep_Learning_Training/Text Classifier/Output_Data/test.json\", embeddings_model_name=\"avsolatorio/GIST-small-Embedding-v0\", tuned_model_name=\"\")\n",
    "parsed_file = tci.parse_file()\n",
    "chunks = tci.pdf_splitter(parsed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabs(premise, hypothesis, tokenizer, model):\n",
    "\n",
    "    # run through model pre-trained on MNLI\n",
    "    input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt', truncation=True)\n",
    "    logits = model(input_ids)[0]\n",
    "    entail_contradiction_logits = logits[:,[0,2]]\n",
    "    probs = entail_contradiction_logits.softmax(dim=1)\n",
    "    true_prob = probs[:,1].item()\n",
    "    return true_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('joeddav/bart-large-mnli-yahoo-answers')  # USING MODEL RAVI FOUND- Worked!\n",
    "model = BartForSequenceClassification.from_pretrained('joeddav/bart-large-mnli-yahoo-answers')  #  USING MODEL RAVI FOUND- Worked!\n",
    "\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"approach to the codes\" is true in datapoint \"0\": 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"register of risks\" is true in datapoint \"0\": 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"automated content moderation (user to user)\" is true in datapoint \"0\": 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"governance and accountability\" is true in datapoint \"0\": 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"icjg\" is true in datapoint \"0\": 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"user reporting and complaints (u2u and search)\" is true in datapoint \"0\": 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"service’s risk assessment\" is true in datapoint \"0\": 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"content moderation (user to user)\" is true in datapoint \"0\": 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that topic \"user access to services (u2u)\" is true in datapoint \"0\": 0.65\n",
      "Probability that topic \"enhanced user control (u2u)\" is true in datapoint \"0\": 0.64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Probability that topic \"approach to the codes\" is true in datapoint \"1\": 0.89\n",
      "Probability that topic \"register of risks\" is true in datapoint \"1\": 0.78\n",
      "Probability that topic \"automated content moderation (user to user)\" is true in datapoint \"1\": 0.03\n",
      "Probability that topic \"governance and accountability\" is true in datapoint \"1\": 0.80\n",
      "Probability that topic \"icjg\" is true in datapoint \"1\": 0.44\n",
      "Probability that topic \"user reporting and complaints (u2u and search)\" is true in datapoint \"1\": 0.04\n",
      "Probability that topic \"service’s risk assessment\" is true in datapoint \"1\": 0.71\n",
      "Probability that topic \"content moderation (user to user)\" is true in datapoint \"1\": 0.08\n",
      "Probability that topic \"user access to services (u2u)\" is true in datapoint \"1\": 0.28\n",
      "Probability that topic \"enhanced user control (u2u)\" is true in datapoint \"1\": 0.48\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Probability that topic \"approach to the codes\" is true in datapoint \"2\": 0.48\n",
      "Probability that topic \"register of risks\" is true in datapoint \"2\": 0.43\n",
      "Probability that topic \"automated content moderation (user to user)\" is true in datapoint \"2\": 0.01\n",
      "Probability that topic \"governance and accountability\" is true in datapoint \"2\": 0.59\n",
      "Probability that topic \"icjg\" is true in datapoint \"2\": 0.71\n",
      "Probability that topic \"user reporting and complaints (u2u and search)\" is true in datapoint \"2\": 0.03\n",
      "Probability that topic \"service’s risk assessment\" is true in datapoint \"2\": 0.18\n",
      "Probability that topic \"content moderation (user to user)\" is true in datapoint \"2\": 0.08\n",
      "Probability that topic \"user access to services (u2u)\" is true in datapoint \"2\": 0.12\n",
      "Probability that topic \"enhanced user control (u2u)\" is true in datapoint \"2\": 0.16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Probability that topic \"approach to the codes\" is true in datapoint \"3\": 0.65\n",
      "Probability that topic \"register of risks\" is true in datapoint \"3\": 0.67\n",
      "Probability that topic \"automated content moderation (user to user)\" is true in datapoint \"3\": 0.08\n",
      "Probability that topic \"governance and accountability\" is true in datapoint \"3\": 0.55\n",
      "Probability that topic \"icjg\" is true in datapoint \"3\": 0.46\n",
      "Probability that topic \"user reporting and complaints (u2u and search)\" is true in datapoint \"3\": 0.06\n",
      "Probability that topic \"service’s risk assessment\" is true in datapoint \"3\": 0.61\n",
      "Probability that topic \"content moderation (user to user)\" is true in datapoint \"3\": 0.19\n",
      "Probability that topic \"user access to services (u2u)\" is true in datapoint \"3\": 0.27\n",
      "Probability that topic \"enhanced user control (u2u)\" is true in datapoint \"3\": 0.22\n",
      "Script 3 Ran!\n"
     ]
    }
   ],
   "source": [
    "Topics = [\"approach to the codes\", \"register of risks\", \"automated content moderation (user to user)\", \"governance and accountability\", \"icjg\", \"user reporting and complaints (u2u and search)\", \"\"\"service’s risk assessment\"\"\", \"content moderation (user to user)\", \"user access to services (u2u)\", \"enhanced user control (u2u)\"]# [\"approach to the codes\", \"automated content moderation (user to user)\", \"governance and accountability\"]\n",
    "\n",
    "\n",
    "for index, chunk in enumerate(chunks):\n",
    "    print(\"\\n\\n\\n\")\n",
    "    premise = chunk.page_content.replace('\\n\\n', '')\n",
    "    # premise = chunks[0].page_content.replace('\\n\\n', '')\n",
    "    for topic in Topics:\n",
    "        hypothesis = f'This text is about {topic}.'\n",
    "\n",
    "        true_prob = get_probabs(premise, hypothesis, tokenizer, model)\n",
    "\n",
    "        print(f'Probability that topic \"{topic}\" is true in datapoint \"{index}\": {true_prob:0.2f}')\n",
    "\n",
    "print('Script 3 Ran!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n \\n\\n \\n\\n \\n \\n\\nOverview \\nThis document is the first of four major consulta�ons that Ofcom, as appointed regulator of the \\nnew Online Safety Act (‘the Act’), will publish as part of our work to establish the new regula�ons \\nover the next 18 months. It focuses on our proposals for how internet services which enable the sharing of user generated \\ncontent (‘user-to-user’ or ‘U2U’ services) and search services should approach their new du�es \\nrela�ng to illegal content. It covers the following areas: the causes and impacts of illegal harms; how \\nservices should assess and mi�gate the risks of illegal harms; how services can iden�fy illegal \\ncontent; and our approach to enforcement. The proposals in this document reflect research we have conducted over the past three years as well \\nas informa�on and evidence gathered through extensive engagement with industry and other \\nexperts. Causes and impacts of illegal harms \\nWe are consul�ng on our assessment of how the priority illegal harms covered by the Act manifest \\nonline, what factors give rise to a risk of these harms and what the impact of the harms is. This \\nanalysis underlines the need for services to take ac�on to combat online harms. It shows that a large \\npropor�on of the UK popula�on has experienced harm online and that the impact of online harms \\ncan, in cases, be extremely severe. Our assessment demonstrates that women, children and groups \\nwith protected characteris�cs are especially likely to be exposed to harm online. Assessing risk \\nWe are consul�ng on the guidance we propose to give about how regulated stakeholders should \\nassess the risk of illegal harm taking place on their services (the ‘Risk Assessment Guidance’), as well \\nas on our proposals about the governance services should put in place to manage risks. This \\ndocument also consults on guidance about how services should keep adequate records of their risk \\nassessments. Services should undertake a robust and comprehensive risk assessment. More specifically, we \\npropose that providers should follow the four-step process set out in Figure 1 below when assessing \\nthe risk of illegal content on their services. We are also proposing that services take several steps to ensure that they have strong governance \\nprocedures in place to mi�gate the risks associated with illegal content. For example, we are \\nproposing that senior governance bodies at large services review the service’s risk management \\nac�vi�es related to online safety at least annually and that all services iden�fy a named senior \\nexecu�ve who is accountable for compliance with the online safety du�es. 2 \\n \\n\\nFigure 1: Proposed four-step process for illegal content risk assessment \\n\\n \\n\\nMitigating risk \\nWe are consul�ng on our illegal harms Codes of Prac�ce, laying out recommended measures that \\nregulated services can take to mi�gate the risk of illegal harm. While the Codes are not binding, and \\nso services can choose to take a different approach to mee�ng their du�es, they act as a ‘safe \\nharbour’. This means any service that implements the recommenda�ons in the Codes would be \\ndeemed to be compliant with its related safety du�es. In the codes we propose to recommend that services put in place a series of measures which, taken \\ntogether, will help combat all of the priority illegal harms in scope of the Act. These measures \\ninclude: \\n\\n• ensuring content modera�on teams are appropriately resourced and trained;  \\n• having easy-to-use systems for users to report poten�ally illegal content and make \\n\\ncomplaints;  \\n• allowing users to block other users or disable comments;  \\n• conduc�ng tests when they update their algorithms that recommend content to users \\n\\n(‘recommender systems’) to assess the risk that the changes would increase the \\ndissemina�on of illegal content; and \\n\\n• a series of recommended steps to make their terms and condi�ons clear and accessible. In addi�on to these cross-cu�ng measures, we propose that relevant services should take a series of \\ntargeted steps to combat Child Sexual Exploita�on and Abuse (CSEA), fraud and terrorism. These \\ntargeted steps include: \\n\\n• Using a technology called ‘hash matching’ to detect and remove known CSAM (Child Sexual \\nAbuse Material). Consistent with the restric�ons in the Act, this proposal does not apply to \\nprivate communica�ons or end-to-end encrypted communica�ons. We are not making any \\nproposals that would involve breaking encryp�on. However, end-to-end encrypted services \\nare s�ll subject to all the safety du�es set out in the Act and will s�ll need to take steps to \\nmi�gate risks of CSAM on their services; \\n\\n• Taking steps to make it harder for perpetrators to groom children online. For example, \\nconfiguring default se�ngs so that children do not appear in lists sugges�ng other users \\nconnect with them; \\n \\n\\n• Deploying keyword detec�on systems to help find and remove posts linked to the sale of \\nstolen creden�als.': {},\n",
       " 'This should help prevent atempts to commit fraud online. We are also \\nrecommending large and high-risk services have dedicated fraud repor�ng channels; \\n\\n\\n\\n \\n\\n \\n\\n3 \\n \\n\\n• Where services operate account verifica�on schemes, they should be transparent about the \\nsteps they are taking to verify accounts. This is aimed at reducing the risk of users being \\ndeceived by posts on fake accounts and should help address fraud and foreign interference in \\nUK processes such as elec�ons; and \\n\\n• Blocking accounts run by banned terrorist organisa�ons. Our analysis suggests that, taken together, these measures will be an effec�ve and propor�onate \\nmeans of tackling the priority illegal harms in scope of the Act.': {},\n",
       " 'Some of the proposals set out in this \\nconsulta�on would apply to all services. However, we are targe�ng many of the more onerous \\nproposals only at services which are large and/or high risk. We provide a full list of all the measures \\nwe are proposing and who they would apply to in our “consulta�on at a glance” which is published \\nalongside this consulta�on. Our proposals will make a contribu�on to comba�ng violence against women and girls online, \\nincluding by se�ng out how services should assess their risk of coercive and controlling behaviour, \\nstalking, harassment and threats, and in�mate image abuse. Our proposals for cross-cu�ng \\nmeasures and some harm specific measures will begin to mi�gate these risks. However, we recognise \\nthat more work is needed in this area, and we will be publishing dra� guidance on how services can \\ncombat violence against women and girls in early 2025. Identifying illegal content \\nA new legal requirement of the Act is for all services to swi�ly take down specific illegal content \\nwhen they become aware of it. Today we are consul�ng on our Illegal Content Judgements Guidance \\n(‘ICJG’). This will provide guidance to services on how they can iden�fy whether a piece of content is \\nlikely to be illegal. Enforcement \\nThe Act gives us significant enforcement powers in the event of non-compliance, including the ability \\nto issue fines of up £18m or up to 10% of the service’s qualifying worldwide revenue (whichever is \\ngreater) and to apply for a court order requiring an internet service provider to withdraw access to \\nthe service to prevent a significant risk of harm to UK users as a result of its failure. 4 \\n \\n\\nNext steps \\nWe welcome comments from stakeholders in response to the proposals set out in this document, \\nincluding any further evidence and suppor�ng informa�on to inform our final decisions.': {},\n",
       " 'The \\nconsulta�on closes on 23 February 2024, and we invite stakeholders to provide responses by this \\ndate. This is also a statutory consulta�on under the Act, and we will engage with specific statutory \\nconsultees through the consulta�on process. For further details of the process for making Codes and \\nguidance, please refer to our Legal Framework (Annex 12). To improve the accessibility of our consulta�on, we are also publishing a “chapter summaries” \\ndocument. It explains what each chapter is about, what proposals we are making, why we are \\nmaking them and what input we would appreciate from stakeholders. Chapter 1 of this document (Introduc�on) provides further informa�on on how services can use and \\nnavigate the document. Annexes 1-4 explain our approach to consulta�ons and how stakeholders \\ncan respond to this consulta�on. Once the consulta�on closes, we will consider stakeholder responses, review our proposals, and \\npublish a statement se�ng out our final decisions in rela�on to our consulta�on proposals, including \\nfinal versions of our guidance and Codes. We currently plan to publish our Statement in Winter 2024. Following our Statement, services will \\nhave three months to conduct their risk assessment. The Codes will also be subject to a \\nparliamentary approval process. We expect this process to conclude by the end of 2024 at which \\npoint the Codes will come into force. This is one of a number of major consulta�ons we will publish as over the next 12-18 months as we \\nput the new online safety regula�ons in place. We provide more detail on our roadmap for \\nimplemen�ng the Online Safety Act at the following link: Crea�ng a safer life online for people in the \\nUK. https://www.ofcom.org.uk/news-centre/2023/safer-life-online-for-people-in-uk\\nhttps://www.ofcom.org.uk/news-centre/2023/safer-life-online-for-people-in-uk\\n\\n\\tOverview\\n\\tCauses and impacts of illegal harms\\n\\tAssessing risk\\n\\tMitigating risk\\n\\tIdentifying illegal content\\n\\tEnforcement\\n\\tNext steps\\n\\n\\n': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to JSON\n",
    "res = tci.create_or_load_json(chunks)\n",
    "# res[i][self.topic] = infer_res['score']\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
